{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q ultralytics\n",
    "#!pip install opencv-python\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\User\\yolo_yo\\predict\\bus.jpg: 640x480 4 persons, 84.3ms\n",
      "Speed: 2.3ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: tensor([[0.9910, 0.9289, 0.9869, 0.4267, 0.9313, 0.9907, 0.9976, 0.9248, 0.9884, 0.9015, 0.9744, 0.9969, 0.9984, 0.9949, 0.9975, 0.9785, 0.9856],\n",
      "        [0.1586, 0.1561, 0.0468, 0.2351, 0.0505, 0.6711, 0.2402, 0.5964, 0.1104, 0.4541, 0.1319, 0.7288, 0.5135, 0.7590, 0.5564, 0.5935, 0.4370],\n",
      "        [0.9894, 0.9335, 0.9794, 0.5549, 0.9086, 0.9952, 0.9976, 0.9465, 0.9778, 0.9134, 0.9481, 0.9983, 0.9987, 0.9954, 0.9964, 0.9774, 0.9804],\n",
      "        [0.0987, 0.0392, 0.0631, 0.0392, 0.0677, 0.2103, 0.2339, 0.2615, 0.3053, 0.3423, 0.3554, 0.2780, 0.2918, 0.2393, 0.2481, 0.1393, 0.1388]])\n",
      "data: tensor([[[1.4236e+02, 4.4186e+02, 9.9095e-01],\n",
      "         [1.4799e+02, 4.3142e+02, 9.2890e-01],\n",
      "         [1.3054e+02, 4.3337e+02, 9.8691e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 4.2672e-01],\n",
      "         [1.0718e+02, 4.4066e+02, 9.3134e-01],\n",
      "         [1.5745e+02, 4.9311e+02, 9.9074e-01],\n",
      "         [9.4264e+01, 4.9925e+02, 9.9755e-01],\n",
      "         [1.7646e+02, 5.5098e+02, 9.2482e-01],\n",
      "         [1.1066e+02, 5.6757e+02, 9.8838e-01],\n",
      "         [1.7422e+02, 5.3235e+02, 9.0151e-01],\n",
      "         [1.6200e+02, 5.3439e+02, 9.7442e-01],\n",
      "         [1.4883e+02, 6.4514e+02, 9.9693e-01],\n",
      "         [9.9666e+01, 6.4941e+02, 9.9845e-01],\n",
      "         [1.7887e+02, 7.4929e+02, 9.9495e-01],\n",
      "         [9.4800e+01, 7.5651e+02, 9.9747e-01],\n",
      "         [1.8598e+02, 8.4975e+02, 9.7854e-01],\n",
      "         [7.3946e+01, 8.5814e+02, 9.8563e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 1.5855e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 1.5608e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 4.6807e-02],\n",
      "         [0.0000e+00, 0.0000e+00, 2.3511e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 5.0521e-02],\n",
      "         [8.0997e+02, 4.8721e+02, 6.7113e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.4024e-01],\n",
      "         [7.8853e+02, 5.6880e+02, 5.9636e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 1.1045e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 4.5411e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 1.3185e-01],\n",
      "         [8.0153e+02, 6.4043e+02, 7.2879e-01],\n",
      "         [8.0040e+02, 6.3644e+02, 5.1345e-01],\n",
      "         [7.6838e+02, 7.3066e+02, 7.5898e-01],\n",
      "         [7.7332e+02, 7.2789e+02, 5.5644e-01],\n",
      "         [7.2683e+02, 8.4367e+02, 5.9346e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 4.3701e-01]],\n",
      "\n",
      "        [[2.9259e+02, 4.5085e+02, 9.8936e-01],\n",
      "         [2.9837e+02, 4.4170e+02, 9.3348e-01],\n",
      "         [2.8318e+02, 4.4337e+02, 9.7940e-01],\n",
      "         [3.0378e+02, 4.4555e+02, 5.5487e-01],\n",
      "         [2.6531e+02, 4.4892e+02, 9.0857e-01],\n",
      "         [3.1815e+02, 4.9541e+02, 9.9517e-01],\n",
      "         [2.5092e+02, 4.9919e+02, 9.9764e-01],\n",
      "         [3.2882e+02, 5.5388e+02, 9.4647e-01],\n",
      "         [2.5059e+02, 5.7485e+02, 9.7776e-01],\n",
      "         [2.7947e+02, 5.3499e+02, 9.1344e-01],\n",
      "         [2.5247e+02, 6.1571e+02, 9.4807e-01],\n",
      "         [3.0349e+02, 6.2994e+02, 9.9828e-01],\n",
      "         [2.5931e+02, 6.2951e+02, 9.9869e-01],\n",
      "         [3.0109e+02, 7.2364e+02, 9.9536e-01],\n",
      "         [2.6114e+02, 7.1774e+02, 9.9643e-01],\n",
      "         [2.8824e+02, 8.0623e+02, 9.7735e-01],\n",
      "         [2.6060e+02, 8.0521e+02, 9.8038e-01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 9.8715e-02],\n",
      "         [0.0000e+00, 0.0000e+00, 3.9226e-02],\n",
      "         [0.0000e+00, 0.0000e+00, 6.3093e-02],\n",
      "         [0.0000e+00, 0.0000e+00, 3.9153e-02],\n",
      "         [0.0000e+00, 0.0000e+00, 6.7749e-02],\n",
      "         [0.0000e+00, 0.0000e+00, 2.1034e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.3390e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.6152e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 3.0528e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 3.4233e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 3.5543e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.7804e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.9177e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.3934e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.4810e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 1.3926e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 1.3879e-01]]])\n",
      "has_visible: True\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([4, 17, 3])\n",
      "xy: tensor([[[142.3645, 441.8609],\n",
      "         [147.9898, 431.4181],\n",
      "         [130.5442, 433.3710],\n",
      "         [  0.0000,   0.0000],\n",
      "         [107.1835, 440.6562],\n",
      "         [157.4519, 493.1140],\n",
      "         [ 94.2637, 499.2470],\n",
      "         [176.4613, 550.9834],\n",
      "         [110.6624, 567.5748],\n",
      "         [174.2182, 532.3488],\n",
      "         [162.0031, 534.3919],\n",
      "         [148.8314, 645.1359],\n",
      "         [ 99.6655, 649.4141],\n",
      "         [178.8723, 749.2934],\n",
      "         [ 94.7997, 756.5117],\n",
      "         [185.9789, 849.7502],\n",
      "         [ 73.9457, 858.1396]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [809.9744, 487.2143],\n",
      "         [  0.0000,   0.0000],\n",
      "         [788.5313, 568.7997],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [801.5266, 640.4258],\n",
      "         [800.4036, 636.4432],\n",
      "         [768.3763, 730.6614],\n",
      "         [773.3247, 727.8928],\n",
      "         [726.8314, 843.6720],\n",
      "         [  0.0000,   0.0000]],\n",
      "\n",
      "        [[292.5922, 450.8507],\n",
      "         [298.3656, 441.7009],\n",
      "         [283.1804, 443.3694],\n",
      "         [303.7812, 445.5459],\n",
      "         [265.3112, 448.9188],\n",
      "         [318.1479, 495.4087],\n",
      "         [250.9237, 499.1886],\n",
      "         [328.8164, 553.8760],\n",
      "         [250.5860, 574.8477],\n",
      "         [279.4675, 534.9937],\n",
      "         [252.4710, 615.7097],\n",
      "         [303.4948, 629.9416],\n",
      "         [259.3111, 629.5056],\n",
      "         [301.0946, 723.6394],\n",
      "         [261.1398, 717.7366],\n",
      "         [288.2359, 806.2347],\n",
      "         [260.5974, 805.2137]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]]])\n",
      "xyn: tensor([[[0.1758, 0.4091],\n",
      "         [0.1827, 0.3995],\n",
      "         [0.1612, 0.4013],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.1323, 0.4080],\n",
      "         [0.1944, 0.4566],\n",
      "         [0.1164, 0.4623],\n",
      "         [0.2179, 0.5102],\n",
      "         [0.1366, 0.5255],\n",
      "         [0.2151, 0.4929],\n",
      "         [0.2000, 0.4948],\n",
      "         [0.1837, 0.5973],\n",
      "         [0.1230, 0.6013],\n",
      "         [0.2208, 0.6938],\n",
      "         [0.1170, 0.7005],\n",
      "         [0.2296, 0.7868],\n",
      "         [0.0913, 0.7946]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [1.0000, 0.4511],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.9735, 0.5267],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.9895, 0.5930],\n",
      "         [0.9882, 0.5893],\n",
      "         [0.9486, 0.6765],\n",
      "         [0.9547, 0.6740],\n",
      "         [0.8973, 0.7812],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3612, 0.4175],\n",
      "         [0.3684, 0.4090],\n",
      "         [0.3496, 0.4105],\n",
      "         [0.3750, 0.4125],\n",
      "         [0.3275, 0.4157],\n",
      "         [0.3928, 0.4587],\n",
      "         [0.3098, 0.4622],\n",
      "         [0.4059, 0.5128],\n",
      "         [0.3094, 0.5323],\n",
      "         [0.3450, 0.4954],\n",
      "         [0.3117, 0.5701],\n",
      "         [0.3747, 0.5833],\n",
      "         [0.3201, 0.5829],\n",
      "         [0.3717, 0.6700],\n",
      "         [0.3224, 0.6646],\n",
      "         [0.3558, 0.7465],\n",
      "         [0.3217, 0.7456]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load a model\n",
    "# yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt 分別對應到 YOLO tiny, small, medium, large, extra-large model\n",
    "# yolo11n.pt, yolo11n-seg, yolo11n-pose, yolo11n-cls 分別進行 image localization, image segmentation, image keypoint detection, image classification\n",
    "# model.track 進行物體追蹤\n",
    "#\n",
    "model = YOLO(\"yolo11n-pose.pt\")  # load an official model\n",
    "# model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "#results = model.track(0, show=True)\n",
    "\n",
    "for r in results:\n",
    "    r.save()\n",
    "    print(r.keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\User\\yolo_yo\\predict\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 129.9ms\n",
      "Speed: 2.0ms preprocess, 129.9ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[119, 146, 172],\n",
      "        [121, 148, 174],\n",
      "        [122, 152, 177],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       [[120, 147, 173],\n",
      "        [122, 149, 175],\n",
      "        [123, 153, 178],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       [[123, 150, 176],\n",
      "        [124, 151, 177],\n",
      "        [125, 155, 180],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[183, 182, 186],\n",
      "        [179, 178, 182],\n",
      "        [180, 179, 183],\n",
      "        ...,\n",
      "        [121, 111, 117],\n",
      "        [113, 103, 109],\n",
      "        [115, 105, 111]],\n",
      "\n",
      "       [[165, 164, 168],\n",
      "        [173, 172, 176],\n",
      "        [187, 186, 190],\n",
      "        ...,\n",
      "        [102,  92,  98],\n",
      "        [101,  91,  97],\n",
      "        [103,  93,  99]],\n",
      "\n",
      "       [[123, 122, 126],\n",
      "        [145, 144, 148],\n",
      "        [176, 175, 179],\n",
      "        ...,\n",
      "        [ 95,  85,  91],\n",
      "        [ 96,  86,  92],\n",
      "        [ 98,  88,  94]]], shape=(1080, 810, 3), dtype=uint8)\n",
      "orig_shape: (1080, 810)\n",
      "path: 'c:\\\\Users\\\\User\\\\yolo_yo\\\\predict\\\\bus.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\segment\\\\predict'\n",
      "speed: {'preprocess': 2.0109000033698976, 'inference': 129.91880002664402, 'postprocess': 9.657399961724877}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n-seg.pt\")  # load an official model\n",
    "# model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "#results = model.track(0, show=True)\n",
    "\n",
    "for r in results:\n",
    "    r.save()\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\User\\yolo_yo\\predict\\bus.jpg: 640x480 4 persons, 1 bus, 67.4ms\n",
      "Speed: 1.9ms preprocess, 67.4ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[119, 146, 172],\n",
      "        [121, 148, 174],\n",
      "        [122, 152, 177],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       [[120, 147, 173],\n",
      "        [122, 149, 175],\n",
      "        [123, 153, 178],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       [[123, 150, 176],\n",
      "        [124, 151, 177],\n",
      "        [125, 155, 180],\n",
      "        ...,\n",
      "        [161, 171, 188],\n",
      "        [160, 170, 187],\n",
      "        [160, 170, 187]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[183, 182, 186],\n",
      "        [179, 178, 182],\n",
      "        [180, 179, 183],\n",
      "        ...,\n",
      "        [121, 111, 117],\n",
      "        [113, 103, 109],\n",
      "        [115, 105, 111]],\n",
      "\n",
      "       [[165, 164, 168],\n",
      "        [173, 172, 176],\n",
      "        [187, 186, 190],\n",
      "        ...,\n",
      "        [102,  92,  98],\n",
      "        [101,  91,  97],\n",
      "        [103,  93,  99]],\n",
      "\n",
      "       [[123, 122, 126],\n",
      "        [145, 144, 148],\n",
      "        [176, 175, 179],\n",
      "        ...,\n",
      "        [ 95,  85,  91],\n",
      "        [ 96,  86,  92],\n",
      "        [ 98,  88,  94]]], shape=(1080, 810, 3), dtype=uint8)\n",
      "orig_shape: (1080, 810)\n",
      "path: 'c:\\\\Users\\\\User\\\\yolo_yo\\\\predict\\\\bus.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 1.895399997010827, 'inference': 67.43170000845566, 'postprocess': 6.38279999839142}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load an official model\n",
    "# model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "#results = model.track(0, show=True)\n",
    "\n",
    "for r in results:\n",
    "    r.save()\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "影片分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "影片播放完畢\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n-pose.pt\")  \n",
    "\n",
    "video_path = \"泰國兩人.mp4\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"無法開啟影片\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # 讀取一幀影像\n",
    "    if not ret:\n",
    "        print(\"影片播放完畢\")\n",
    "        break  # 影片播放完則跳出迴圈\n",
    "\n",
    "    # 進行 YOLO 追蹤\n",
    "    results = model.track(frame, persist=True)\n",
    "\n",
    "    if results is not None and len(results) > 0:\n",
    "        for r in results:\n",
    "            annotated_frame = r.plot()  # 繪製偵測框\n",
    "            \n",
    "            # 提取關節點資訊\n",
    "            if hasattr(r, \"keypoints\") and r.keypoints is not None:\n",
    "                keypoints = r.keypoints.xy  # 獲取 keypoints 的 (x, y) 座標\n",
    "\n",
    "                if keypoints is not None:\n",
    "                    for kp in keypoints:  # 遍歷每個偵測到的物件\n",
    "                        for x, y in kp:  # 遍歷該物件的所有關節點\n",
    "                            x, y = int(x), int(y)  # 轉換為整數座標\n",
    "                            cv.circle(annotated_frame, (x, y), 5, (0, 255, 0), -1)  # 畫上關節點\n",
    "                            cv.putText(annotated_frame, f\"({x},{y})\", (x+5, y-5),\n",
    "                                       cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)  # 顯示座標\n",
    "            \n",
    "            # 調整影像大小\n",
    "            new_width, new_height = 950, 680\n",
    "            annotated_frame = cv.resize(annotated_frame, (new_width, new_height))\n",
    "\n",
    "            # 顯示結果\n",
    "            cv.imshow(\"YOLO Pose Estimation\", annotated_frame)\n",
    "    \n",
    "    # 按 `空白鍵` 退出\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord(' '):  \n",
    "        break  # 跳出 while 迴圈，關閉視窗\n",
    "\n",
    "# 釋放資源\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "警告1: 關節的移動速度是否超過閾值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 初始化 YOLO 模型\n",
    "model = YOLO(\"yolo11n-pose.pt\")\n",
    "\n",
    "# 影片讀取\n",
    "video_path = \"泰國兩人.mp4\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"無法開啟影片\")\n",
    "    exit()\n",
    "\n",
    "# 紀錄上一幀的時間和關節位置\n",
    "previous_time = time.time()\n",
    "previous_keypoints = {}\n",
    "\n",
    "# 設定速度閾值 (單位: 像素/秒)\n",
    "speed_threshold_wirst = 300  \n",
    "speed_threshold_knee = 350  \n",
    "speed_threshold_ankle =400  \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"影片播放完畢\")\n",
    "        break\n",
    "\n",
    "    # 進行 YOLO 偵測\n",
    "    results = model.track(frame, persist=True)\n",
    "\n",
    "    current_time = time.time()\n",
    "    time_diff = current_time - previous_time  # 計算時間間隔\n",
    "\n",
    "    if results is not None and len(results) > 0:\n",
    "        for person_id, r in enumerate(results):\n",
    "            annotated_frame = r.plot()\n",
    "\n",
    "            if hasattr(r, \"keypoints\") and r.keypoints is not None:\n",
    "                keypoints = r.keypoints.xy.numpy()\n",
    "\n",
    "                if keypoints is not None and len(keypoints) > 0:\n",
    "                     for pid, person_kp in enumerate(keypoints):\n",
    "                          if len(person_kp) >= 17:  # 確保至少有 17 個關節點\n",
    "                               left_wirst = person_kp[9]  # (x, y)\n",
    "                               right_wirst = person_kp[10]\n",
    "                               left_knee = person_kp[13]\n",
    "                               right_knee = person_kp[14]\n",
    "                               left_ankle = person_kp[15]\n",
    "                               right_ankle = person_kp[16]\n",
    "                               \n",
    "                               prev_left_wirst = previous_keypoints.get(f\"{pid}_left_wirst\", left_wirst)\n",
    "                               prev_right_wirst = previous_keypoints.get(f\"{pid}_right_wirst\", right_wirst)\n",
    "                               prev_left_knee = previous_keypoints.get(f\"{pid}_left_knee\", left_knee)\n",
    "                               prev_right_knee = previous_keypoints.get(f\"{pid}_right_knee\", right_knee)\n",
    "                               prev_left_ankle = previous_keypoints.get(f\"{pid}_left_ankle\", left_ankle)\n",
    "                               prev_right_ankle = previous_keypoints.get(f\"{pid}_right_ankle\", right_ankle)\n",
    "                               \n",
    "                               left_wirst_speed = np.linalg.norm(left_wirst - prev_left_wirst) / time_diff\n",
    "                               right_wirst_speed = np.linalg.norm(right_wirst - prev_right_wirst) / time_diff\n",
    "                               left_knee_speed = np.linalg.norm(left_knee - prev_left_knee) / time_diff\n",
    "                               right_knee_speed = np.linalg.norm(right_knee - prev_right_knee) / time_diff\n",
    "                               left_ankle_speed = np.linalg.norm(left_ankle - prev_left_ankle) / time_diff\n",
    "                               right_ankle_speed = np.linalg.norm(right_ankle - prev_right_ankle) / time_diff\n",
    "                               \n",
    "                               # 更新上一幀的關節座標\n",
    "                               previous_keypoints[f\"{pid}_left_wirst\"] = left_wirst\n",
    "                               previous_keypoints[f\"{pid}_right_wirst\"] = right_wirst\n",
    "                               previous_keypoints[f\"{pid}_left_knee\"] = left_knee\n",
    "                               previous_keypoints[f\"{pid}_right_knee\"] = right_knee\n",
    "                               previous_keypoints[f\"{pid}_left_ankle\"] = left_ankle\n",
    "                               previous_keypoints[f\"{pid}_right_ankle\"] = right_ankle\n",
    "                               \n",
    "                                # 畫出手肘與膝蓋關節\n",
    "                               for x, y in [left_wirst, right_wirst, left_knee, right_knee, left_ankle, right_ankle]:\n",
    "                                   x, y = int(x), int(y)\n",
    "                                   cv.circle(annotated_frame, (x, y), 5, (0, 255, 0), -1)\n",
    "                                   cv.putText(annotated_frame, f\"({x},{y})\", (x + 5, y - 5),\n",
    "                                              cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "\n",
    "                        # 判斷是否超速\n",
    "                               if left_wirst_speed > speed_threshold_wirst or right_wirst_speed > speed_threshold_wirst:\n",
    "                                   cv.putText(annotated_frame, \"Warning: Fast wirst Movement!\",\n",
    "                                       (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                               if left_knee_speed > speed_threshold_knee or right_knee_speed > speed_threshold_knee:\n",
    "                                   cv.putText(annotated_frame, \"Warning: Fast Knee Movement!\",\n",
    "                                       (50, 100), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                               if left_ankle_speed > speed_threshold_ankle or right_ankle_speed > speed_threshold_ankle:\n",
    "                                   cv.putText(annotated_frame, \"Warning: Fast Ankle Movement!\",\n",
    "                                       (50, 150), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # 調整影像大小\n",
    "            new_width, new_height = 950, 680\n",
    "            annotated_frame = cv.resize(annotated_frame, (new_width, new_height))\n",
    "\n",
    "            # 顯示結果\n",
    "            cv.imshow(\"YOLO Pose Estimation\", annotated_frame)\n",
    "\n",
    "    # 更新時間\n",
    "    previous_time = current_time\n",
    "\n",
    "    # 按 `空白鍵` 退出\n",
    "    key = cv.waitKey(10) & 0xFF\n",
    "    if key == ord(' '):\n",
    "        break\n",
    "\n",
    "# 釋放資源\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "警告2:腰部扭動+手部移動速度過快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "被警告的ID: []\n",
      "影片播放完畢\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 初始化 YOLO 模型\n",
    "model = YOLO(\"yolo11n-pose.pt\")\n",
    "\n",
    "# 影片讀取\n",
    "video_path = \"泰國兩人.mp4\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"無法開啟影片\")\n",
    "    exit()\n",
    "\n",
    "previous_time = time.time()\n",
    "previous_keypoints = {}\n",
    "\n",
    "threshold_wrist = 250\n",
    "threshold_elbow = 200\n",
    "\n",
    "warned_ids = []\n",
    "\n",
    "# 判斷是否為旋轉（肩膀-骨盆向量角度變化）\n",
    "def is_shoulder_to_hip_rotated(prev_shoulder, curr_shoulder, prev_hip, curr_hip, angle_threshold_cos=0.3):\n",
    "    vec_prev = prev_shoulder - prev_hip\n",
    "    vec_curr = curr_shoulder - curr_hip\n",
    "    if np.linalg.norm(vec_prev) == 0 or np.linalg.norm(vec_curr) == 0:\n",
    "        return False\n",
    "    cos_sim = np.dot(vec_prev, vec_curr) / (np.linalg.norm(vec_prev) * np.linalg.norm(vec_curr))\n",
    "    return cos_sim < angle_threshold_cos\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"影片播放完畢\")\n",
    "        break\n",
    "\n",
    "    results = model.track(frame, persist=True, tracker=\"botsort.yaml\")\n",
    "    current_time = time.time()\n",
    "    time_diff = current_time - previous_time\n",
    "\n",
    "    if results is not None and len(results) > 0:\n",
    "        for r in results:\n",
    "            annotated_frame = r.plot()\n",
    "\n",
    "            if hasattr(r, \"keypoints\") and r.keypoints is not None:\n",
    "                keypoints = r.keypoints.xy.numpy()\n",
    "\n",
    "                if keypoints is not None and len(keypoints) > 0:\n",
    "                    for idx, person_kp in enumerate(keypoints):\n",
    "                        track_id = int(r.id[idx]) if hasattr(r, \"id\") and r.id is not None else idx\n",
    "\n",
    "                        # 關鍵點\n",
    "                        left_wrist = person_kp[9]\n",
    "                        right_wrist = person_kp[10]\n",
    "                        left_elbow = person_kp[7]\n",
    "                        right_elbow = person_kp[8]\n",
    "                        left_hip = person_kp[11]\n",
    "                        right_hip = person_kp[12]\n",
    "                        center_hip = (left_hip + right_hip) / 2\n",
    "                        left_shoulder = person_kp[5]\n",
    "                        right_shoulder = person_kp[6]\n",
    "                        center_shoulder = (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "                        # 前一幀的資料\n",
    "                        prev_left_wrist = previous_keypoints.get(f\"{track_id}_left_wrist\", left_wrist)\n",
    "                        prev_right_wrist = previous_keypoints.get(f\"{track_id}_right_wrist\", right_wrist)\n",
    "                        prev_left_elbow = previous_keypoints.get(f\"{track_id}_left_elbow\", left_elbow)\n",
    "                        prev_right_elbow = previous_keypoints.get(f\"{track_id}_right_elbow\", right_elbow)\n",
    "                        prev_center_hip = previous_keypoints.get(f\"{track_id}_center_hip\", center_hip)\n",
    "                        prev_left_shoulder = previous_keypoints.get(f\"{track_id}_left_shoulder\", left_shoulder)\n",
    "                        prev_right_shoulder = previous_keypoints.get(f\"{track_id}_right_shoulder\", right_shoulder)\n",
    "\n",
    "                        # 計算速度\n",
    "                        lw_speed = np.linalg.norm(left_wrist - prev_left_wrist) / time_diff\n",
    "                        rw_speed = np.linalg.norm(right_wrist - prev_right_wrist) / time_diff\n",
    "                        le_speed = np.linalg.norm(left_elbow - prev_left_elbow) / time_diff\n",
    "                        re_speed = np.linalg.norm(right_elbow - prev_right_elbow) / time_diff\n",
    "\n",
    "                        # 判斷旋轉\n",
    "                        shoulder_rotated = is_shoulder_to_hip_rotated(\n",
    "                            (prev_left_shoulder + prev_right_shoulder) / 2,\n",
    "                            center_shoulder,\n",
    "                            prev_center_hip,\n",
    "                            center_hip\n",
    "                        )\n",
    "\n",
    "                        # 是否手移動快\n",
    "                        fast_right = rw_speed > threshold_wrist or re_speed > threshold_elbow\n",
    "                        fast_left = lw_speed > threshold_wrist or le_speed > threshold_elbow\n",
    "\n",
    "                        # 是否對應肩膀有上抬（Y軸變小表示上升）\n",
    "                        right_shoulder_raised = prev_right_shoulder[1] - right_shoulder[1] > 10\n",
    "                        left_shoulder_raised = prev_left_shoulder[1] - left_shoulder[1] > 10\n",
    "\n",
    "                        y_base = 50 + idx * 60\n",
    "                        if (fast_right and shoulder_rotated and right_shoulder_raised) or \\\n",
    "                           (fast_left and shoulder_rotated and left_shoulder_raised):\n",
    "                            cv.putText(annotated_frame, f\"⚠ Abnormal Movement - Person {track_id}\",\n",
    "                                       (50, y_base), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                            if track_id not in warned_ids:\n",
    "                                warned_ids.append(track_id)\n",
    "\n",
    "                        # 畫點\n",
    "                        for x, y in [left_wrist, right_wrist, left_elbow, right_elbow]:\n",
    "                            x, y = int(x), int(y)\n",
    "                            cv.circle(annotated_frame, (x, y), 5, (0, 255, 0), -1)\n",
    "                            cv.putText(annotated_frame, f\"({x},{y})\", (x + 5, y - 5),\n",
    "                                       cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "\n",
    "                        # 更新關鍵點\n",
    "                        previous_keypoints[f\"{track_id}_left_wrist\"] = left_wrist\n",
    "                        previous_keypoints[f\"{track_id}_right_wrist\"] = right_wrist\n",
    "                        previous_keypoints[f\"{track_id}_left_elbow\"] = left_elbow\n",
    "                        previous_keypoints[f\"{track_id}_right_elbow\"] = right_elbow\n",
    "                        previous_keypoints[f\"{track_id}_center_hip\"] = center_hip\n",
    "                        previous_keypoints[f\"{track_id}_left_shoulder\"] = left_shoulder\n",
    "                        previous_keypoints[f\"{track_id}_right_shoulder\"] = right_shoulder\n",
    "\n",
    "            print(f\"被警告的ID: {warned_ids}\")\n",
    "\n",
    "            annotated_frame = cv.resize(annotated_frame, (950, 680))\n",
    "            cv.imshow(\"YOLO Pose Estimation\", annotated_frame)\n",
    "\n",
    "    previous_time = current_time\n",
    "\n",
    "    if cv.waitKey(10) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO + MediaPipe + 正規化 (拳頭 + 彎手肘 + 高速手速) (忽略跳動過大數據)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID: [0]\n",
      "被警告的ID: [0]\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "被警告的ID:\n",
      "影片播放完畢\n",
      "\n",
      "=== 所有人平均骨架速度（正規化） ===\n",
      "ID 0\n",
      "左手腕：48.05\n",
      "右手腕：69.62\n",
      "骨  盆：19.28\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "import logging\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "# 初始化 YOLO Pose 模型與 MediaPipe 手部模型\n",
    "model = YOLO(\"yolo11n-pose.pt\")\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.6)\n",
    "\n",
    "video_path = \"打人.mp4\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"無法開啟影片\")\n",
    "    exit()\n",
    "\n",
    "previous_time = time.time()\n",
    "previous_keypoints = {}\n",
    "warned_ids = []\n",
    "seen_ids = set()\n",
    "all_speeds = {}\n",
    "scale_histories = {}\n",
    "prev_gesture = {}\n",
    "\n",
    "threshold_speed = 350\n",
    "angle_threshold = 90  # 手肘夾角\n",
    "gesture_change_frame_limit = 10\n",
    "SCALE_HISTORY_LEN = 5\n",
    "SCALE_JUMP_THRESHOLD = 1.8\n",
    "\n",
    "# 計算兩向量夾角（用於手肘）\n",
    "def calc_angle(a, b, c):\n",
    "    v1, v2 = a - b, c - b\n",
    "    unit_v1 = v1 / np.linalg.norm(v1)\n",
    "    unit_v2 = v2 / np.linalg.norm(v2)\n",
    "    dot = np.dot(unit_v1, unit_v2)\n",
    "    dot = np.clip(dot, -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(dot))\n",
    "\n",
    "# MediaPipe\n",
    "def is_fist(hand_landmarks):\n",
    "    tips_ids = [4, 8, 12, 16, 20]\n",
    "    extended = 0\n",
    "    for i in tips_ids[1:]:\n",
    "        if hand_landmarks.landmark[i].y < hand_landmarks.landmark[i - 2].y:\n",
    "            extended += 1\n",
    "    return extended < 1 \n",
    "\n",
    "def estimate_scale(person_kp):\n",
    "    lsh, rsh = person_kp[5], person_kp[6]\n",
    "    lhip, rhip = person_kp[11], person_kp[12]\n",
    "    center_shoulder = (lsh + rsh) / 2\n",
    "    center_hip = (lhip + rhip) / 2\n",
    "    dist = np.linalg.norm(center_shoulder - center_hip)\n",
    "    return 100 / dist if dist > 0 else 1.0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"影片播放完畢\")\n",
    "        break\n",
    "\n",
    "    results = model.track(frame, persist=True, tracker=\"botsort.yaml\")\n",
    "    current_time = time.time()\n",
    "    dt = current_time - previous_time\n",
    "    current_warned_ids = []\n",
    "\n",
    "    img_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    hand_results = hands.process(img_rgb)\n",
    "\n",
    "    if results:\n",
    "        for r in results:\n",
    "            if not (hasattr(r, \"keypoints\") and r.keypoints.xy is not None):\n",
    "                continue\n",
    "\n",
    "            kps = r.keypoints.xy.numpy()\n",
    "            for idx, kp in enumerate(kps):\n",
    "                track_id = int(r.id[idx]) if hasattr(r, \"id\") and r.id is not None else idx\n",
    "                seen_ids.add(track_id)\n",
    "                all_speeds.setdefault(track_id, {\"lw\": [], \"rw\": [], \"hip\": []})\n",
    "\n",
    "                lw, rw = kp[9], kp[10]\n",
    "                le, re = kp[7], kp[8]\n",
    "                lsh, rsh = kp[5], kp[6]\n",
    "                lhip, rhip = kp[11], kp[12]\n",
    "                ch = (lhip + rhip) / 2\n",
    "\n",
    "                curr_scale = estimate_scale(kp)\n",
    "                scale_histories.setdefault(track_id, deque(maxlen=SCALE_HISTORY_LEN))\n",
    "                if len(scale_histories[track_id]) > 0:\n",
    "                    avg_scale = np.mean(scale_histories[track_id])\n",
    "                    if curr_scale > avg_scale * SCALE_JUMP_THRESHOLD or curr_scale < avg_scale / SCALE_JUMP_THRESHOLD:\n",
    "                        continue\n",
    "                scale_histories[track_id].append(curr_scale)\n",
    "                smooth_scale = np.mean(scale_histories[track_id])\n",
    "\n",
    "                prev_lw = previous_keypoints.get(f\"{track_id}_lw\", lw)\n",
    "                prev_rw = previous_keypoints.get(f\"{track_id}_rw\", rw)\n",
    "                prev_ch = previous_keypoints.get(f\"{track_id}_ch\", ch)\n",
    "\n",
    "                lw_speed = np.linalg.norm((lw - prev_lw) * smooth_scale) / dt\n",
    "                rw_speed = np.linalg.norm((rw - prev_rw) * smooth_scale) / dt\n",
    "                hip_speed = np.linalg.norm((ch - prev_ch) * smooth_scale) / dt\n",
    "\n",
    "                all_speeds[track_id][\"lw\"].append(lw_speed)\n",
    "                all_speeds[track_id][\"rw\"].append(rw_speed)\n",
    "                all_speeds[track_id][\"hip\"].append(hip_speed)\n",
    "\n",
    "                # ===== 手肘角度偵測 =====\n",
    "                left_angle = calc_angle(lw, le, lsh)\n",
    "                right_angle = calc_angle(rw, re, rsh)\n",
    "                elbow_punch = left_angle < angle_threshold or right_angle < angle_threshold\n",
    "\n",
    "                # ===== MediaPipe 偵測手勢（是否拳頭）=====\n",
    "                is_current_fist = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hl in hand_results.multi_hand_landmarks:\n",
    "                        if is_fist(hl):\n",
    "                            is_current_fist = True\n",
    "                            break\n",
    "\n",
    "                # ===== 整合判斷：快速 + 彎手 + 拳頭 =====\n",
    "                fast_hands = lw_speed > threshold_speed or rw_speed > threshold_speed\n",
    "                abnormal = fast_hands and elbow_punch and is_current_fist\n",
    "\n",
    "                if abnormal:\n",
    "                    current_warned_ids.append(track_id)\n",
    "                    if track_id not in warned_ids:\n",
    "                        warned_ids.append(track_id)\n",
    "\n",
    "                previous_keypoints[f\"{track_id}_lw\"] = lw\n",
    "                previous_keypoints[f\"{track_id}_rw\"] = rw\n",
    "                previous_keypoints[f\"{track_id}_ch\"] = ch\n",
    "\n",
    "            annotated = r.plot()\n",
    "            annotated = cv.resize(annotated, (950, 680))\n",
    "            cv.imshow(\"打人動作偵測\", annotated)\n",
    "\n",
    "    print(f\"被警告的ID: {current_warned_ids}\" if current_warned_ids else \"被警告的ID:\")\n",
    "    previous_time = current_time\n",
    "\n",
    "    if cv.waitKey(10) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"\\n=== 所有人平均骨架速度（正規化） ===\")\n",
    "for track_id in sorted(seen_ids):\n",
    "    speeds = all_speeds[track_id]\n",
    "    print(f\"ID {track_id}\")\n",
    "    print(f\"左手腕：{np.mean(speeds['lw']):.2f}\")\n",
    "    print(f\"右手腕：{np.mean(speeds['rw']):.2f}\")\n",
    "    print(f\"骨  盆：{np.mean(speeds['hip']):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即時分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 87.9ms\n",
      "Speed: 3.8ms preprocess, 87.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.6ms\n",
      "Speed: 1.8ms preprocess, 74.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.4ms\n",
      "Speed: 1.7ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.6ms\n",
      "Speed: 1.7ms preprocess, 68.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.8ms\n",
      "Speed: 1.7ms preprocess, 84.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.1ms\n",
      "Speed: 1.5ms preprocess, 68.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.1ms\n",
      "Speed: 1.7ms preprocess, 69.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.1ms\n",
      "Speed: 1.6ms preprocess, 70.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.5ms\n",
      "Speed: 1.6ms preprocess, 71.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.0ms\n",
      "Speed: 1.9ms preprocess, 69.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.4ms\n",
      "Speed: 1.7ms preprocess, 71.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.0ms\n",
      "Speed: 1.6ms preprocess, 68.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.5ms\n",
      "Speed: 1.8ms preprocess, 69.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.9ms\n",
      "Speed: 1.6ms preprocess, 66.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.5ms\n",
      "Speed: 1.7ms preprocess, 67.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.4ms\n",
      "Speed: 1.9ms preprocess, 68.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.9ms\n",
      "Speed: 1.6ms preprocess, 69.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.3ms\n",
      "Speed: 1.6ms preprocess, 67.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.3ms\n",
      "Speed: 1.6ms preprocess, 67.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.8ms\n",
      "Speed: 1.7ms preprocess, 66.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.6ms\n",
      "Speed: 1.6ms preprocess, 66.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.7ms\n",
      "Speed: 1.8ms preprocess, 67.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.1ms\n",
      "Speed: 1.6ms preprocess, 68.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.2ms\n",
      "Speed: 1.7ms preprocess, 68.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.2ms\n",
      "Speed: 1.8ms preprocess, 69.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.7ms\n",
      "Speed: 3.0ms preprocess, 71.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.1ms\n",
      "Speed: 1.7ms preprocess, 68.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.5ms\n",
      "Speed: 3.3ms preprocess, 73.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.0ms\n",
      "Speed: 1.8ms preprocess, 67.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.9ms\n",
      "Speed: 2.0ms preprocess, 68.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.6ms\n",
      "Speed: 1.8ms preprocess, 67.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.8ms\n",
      "Speed: 1.8ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.8ms\n",
      "Speed: 1.7ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.0ms\n",
      "Speed: 1.7ms preprocess, 70.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.2ms\n",
      "Speed: 1.9ms preprocess, 81.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.4ms\n",
      "Speed: 1.7ms preprocess, 67.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 1.6ms preprocess, 83.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.0ms\n",
      "Speed: 1.7ms preprocess, 75.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.4ms\n",
      "Speed: 1.8ms preprocess, 68.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 67.9ms\n",
      "Speed: 1.6ms preprocess, 67.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.0ms\n",
      "Speed: 2.5ms preprocess, 88.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 65.0ms\n",
      "Speed: 1.6ms preprocess, 65.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.1ms\n",
      "Speed: 2.2ms preprocess, 67.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.6ms\n",
      "Speed: 2.1ms preprocess, 70.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.0ms\n",
      "Speed: 1.9ms preprocess, 75.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.3ms\n",
      "Speed: 2.2ms preprocess, 76.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.8ms\n",
      "Speed: 1.9ms preprocess, 67.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.2ms\n",
      "Speed: 1.8ms preprocess, 69.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.5ms\n",
      "Speed: 1.9ms preprocess, 66.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 66.4ms\n",
      "Speed: 1.8ms preprocess, 66.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.1ms\n",
      "Speed: 1.9ms preprocess, 86.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 65.2ms\n",
      "Speed: 1.8ms preprocess, 65.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.0ms\n",
      "Speed: 1.8ms preprocess, 88.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.5ms\n",
      "Speed: 1.8ms preprocess, 74.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.9ms\n",
      "Speed: 1.9ms preprocess, 68.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.1ms\n",
      "Speed: 2.0ms preprocess, 76.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.0ms\n",
      "Speed: 1.8ms preprocess, 68.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.3ms\n",
      "Speed: 2.0ms preprocess, 66.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.0ms\n",
      "Speed: 2.1ms preprocess, 66.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.3ms\n",
      "Speed: 1.9ms preprocess, 89.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 63.6ms\n",
      "Speed: 1.6ms preprocess, 63.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "\n",
    "model = YOLO(\"yolo11n-pose.pt\")\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "new_width = 750\n",
    "new_height = 550\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv.flip(frame, 1)  # 左右翻轉\n",
    "    frame = cv.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # 進行 YOLO 姿態偵測\n",
    "    results = model.track(frame, persist=False)\n",
    "\n",
    "    # 繪製偵測結果\n",
    "    if results:\n",
    "        for r in results:\n",
    "            annotated_frame = r.plot()  # 繪製偵測框\n",
    "            \n",
    "            # 提取關節點資訊\n",
    "            keypoints = r.keypoints.xy  # 獲取 keypoints 的 (x, y) 座標\n",
    "\n",
    "            if keypoints is not None:\n",
    "                for kp in keypoints:  # 遍歷每個偵測到的物件\n",
    "                    for x, y in kp:  # 遍歷該物件的所有關節點\n",
    "                        x, y = int(x), int(y)  # 轉換為整數座標\n",
    "                        cv.circle(annotated_frame, (x, y), 5, (0, 255, 0), -1)  # 畫上關節點\n",
    "                        cv.putText(annotated_frame, f\"({x},{y})\", (x+5, y-5),\n",
    "                                   cv.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)  # 顯示座標\n",
    "\n",
    "            cv.imshow(\"YOLO Pose Detection\", annotated_frame)\n",
    "\n",
    "    if cv.waitKey(10) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# 釋放資源\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "412770538",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
